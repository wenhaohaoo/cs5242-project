{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1636949219107,
     "user": {
      "displayName": "Xiaoxin He",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15594701126788275752"
     },
     "user_tz": -480
    },
    "id": "nEOSIYyWFjdF",
    "outputId": "b58f26aa-ec08-4ffa-a022-67e14a694cd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1636949219635,
     "user": {
      "displayName": "Xiaoxin He",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15594701126788275752"
     },
     "user_tz": -480
    },
    "id": "BJrg4XQFFrND",
    "outputId": "5146cd4d-edfb-4e0e-b3bd-b5fca2f7dce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/cs5242-project\n",
      "/content/drive/My Drive/cs5242-project\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/cs5242-project\n",
    "!pwd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1636949219636,
     "user": {
      "displayName": "Xiaoxin He",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15594701126788275752"
     },
     "user_tz": -480
    },
    "id": "InegDHclF7kK",
    "outputId": "eb12b2ed-9080-4867-ceec-195722fbf4d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'validation', 'train.csv', 'test.csv']\n",
      "Train Classes - ['disgusted', 'happy', 'neutral', 'surprised', 'scared', 'sad', 'angry']\n",
      "Validation Classes - ['surprised', 'disgusted', 'neutral', 'angry', 'sad', 'scared', 'happy']\n"
     ]
    }
   ],
   "source": [
    "# Looking into the directory\n",
    "data_dir = './dataset'\n",
    "print(os.listdir(data_dir))\n",
    "classes_train = os.listdir(data_dir + \"/train\")\n",
    "classes_valid = os.listdir(data_dir + \"/validation\")\n",
    "print(f'Train Classes - {classes_train}')\n",
    "print(f'Validation Classes - {classes_valid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sf7QKElCGO1D"
   },
   "outputs": [],
   "source": [
    "# Data transforms (Gray Scaling & data augmentation)\n",
    "train_tfms = tt.Compose([tt.Grayscale(num_output_channels=1),\n",
    "                         tt.RandomHorizontalFlip(),\n",
    "                         tt.RandomRotation(30),\n",
    "                         tt.Resize((32,32)),\n",
    "                         tt.ToTensor()])\n",
    "\n",
    "valid_tfms = tt.Compose([tt.Grayscale(num_output_channels=1), tt.Resize((32,32)), tt.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqWKT3vUGVdS"
   },
   "outputs": [],
   "source": [
    "# Emotion Detection datasets\n",
    "train_ds = ImageFolder(data_dir + '/train', train_tfms)\n",
    "valid_ds = ImageFolder(data_dir + '/validation', valid_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIHNJRJ1GVxl"
   },
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXBcuRksGXGg"
   },
   "outputs": [],
   "source": [
    "# PyTorch data loaders\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1636949220079,
     "user": {
      "displayName": "Xiaoxin He",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15594701126788275752"
     },
     "user_tz": -480
    },
    "id": "Yvgh307uGYZB",
    "outputId": "f0666395-0ee2-45fe-cc07-f51bf8cadd4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Neural Networks\n",
    "\n",
    "Over here, we train a simple VGG, a Very Deep Convolutional Networks for Large-Scale Image Recognition which was propsed by Visual Geometry Group in 2014.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "439DHtA_G2JU"
   },
   "outputs": [],
   "source": [
    "class VGG_convnet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(VGG_convnet, self).__init__()\n",
    "\n",
    "        # block 1:         1 x 32 x 32 --> 64 x 16 x 16        \n",
    "        self.conv1a = nn.Conv2d(1,   64,  kernel_size=3, padding=1 )\n",
    "        self.conv1b = nn.Conv2d(64,  64,  kernel_size=3, padding=1 )\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        self.conv2a = nn.Conv2d(64,  128, kernel_size=3, padding=1 )\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1 )\n",
    "        self.pool2  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4        \n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1 )\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1 )\n",
    "        self.pool3  = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1 )\n",
    "        self.pool4  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        self.linear1 = nn.Linear(2048, 4096)\n",
    "        self.linear2 = nn.Linear(4096,4096)\n",
    "        self.linear3 = nn.Linear(4096, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1:         3 x 32 x 32 --> 64 x 16 x 16\n",
    "        x = self.conv1a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # block 2:         64 x 16 x 16 --> 128 x 8 x 8\n",
    "        x = self.conv2a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
    "        x = self.conv3a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        #block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        x = self.conv4a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        x = x.view(-1, 2048)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1636949220079,
     "user": {
      "displayName": "Xiaoxin He",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15594701126788275752"
     },
     "user_tz": -480
    },
    "id": "VxvjrktkHZ1k",
    "outputId": "fdaf561d-77a3-478c-ca2b-0ef9a28307b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG_convnet(\n",
      "  (conv1a): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2a): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "  (linear2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (linear3): Linear(in_features=4096, out_features=10, bias=True)\n",
      ")\n",
      "There are 27539402 (27.54 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "net=VGG_convnet()\n",
    "\n",
    "print(net)\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NBy2SEu3HgaP"
   },
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9meTEHCkHiJv"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "my_lr=0.25  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd2tU9rHHm6t"
   },
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "\n",
    "    for minibatch_data, minibatch_label in valid_dl:\n",
    "        # send them to the gpu\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "\n",
    "        # reshape the minibatch\n",
    "        inputs = minibatch_data.view(-1, 1, 32, 32)\n",
    "\n",
    "        # feed it to the network\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        # compute the error made on this batch\n",
    "        error = utils.get_error( scores , minibatch_label)\n",
    "\n",
    "        # add it to the running error\n",
    "        running_error += error.item()\n",
    "\n",
    "        num_batches+=1\n",
    "\n",
    "\n",
    "    # compute error rate on the full test set\n",
    "    total_error = running_error/num_batches\n",
    "\n",
    "    print( 'error rate on test set =', total_error*100 ,'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2127525,
     "status": "ok",
     "timestamp": 1636951348097,
     "user": {
      "displayName": "Xiaoxin He",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15594701126788275752"
     },
     "user_tz": -480
    },
    "id": "T-Iaco5uHrOW",
    "outputId": "4f7b78e1-7b86-4ede-cf06-cf9848bae142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 0.16052822271982828 min \t lr= 0.25 \t loss= 2.019545246645347 \t error= 82.12371173593186 percent\n",
      "error rate on test set = 81.45454525947571 percent\n",
      " \n",
      "epoch= 2 \t time= 0.33595306078592935 min \t lr= 0.25 \t loss= 1.9555120480429267 \t error= 82.08247478475276 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 3 \t time= 0.5116730650266011 min \t lr= 0.25 \t loss= 1.9491242944579763 \t error= 82.30927869216683 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 4 \t time= 0.6883858442306519 min \t lr= 0.25 \t loss= 1.9464216392064833 \t error= 81.62886629399566 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 5 \t time= 0.8643346468607584 min \t lr= 0.25 \t loss= 1.9442517732836537 \t error= 81.29896933270484 percent\n",
      "error rate on test set = 87.09090948104858 percent\n",
      " \n",
      "epoch= 6 \t time= 1.036573048432668 min \t lr= 0.25 \t loss= 1.9432222646536286 \t error= 81.83505227885294 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 7 \t time= 1.2103716532389324 min \t lr= 0.25 \t loss= 1.9440146930438955 \t error= 81.56701074433082 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 8 \t time= 1.380284357070923 min \t lr= 0.25 \t loss= 1.9418596520866316 \t error= 81.85567063154635 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 9 \t time= 1.5512093901634216 min \t lr= 0.25 \t loss= 1.9423316237852746 \t error= 81.2783507342191 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 10 \t time= 1.7207258065541586 min \t lr= 0.125 \t loss= 1.9383834674186313 \t error= 80.9072171904377 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 11 \t time= 1.8945247769355773 min \t lr= 0.125 \t loss= 1.9375313876830424 \t error= 80.7422682182076 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 12 \t time= 2.066851802666982 min \t lr= 0.125 \t loss= 1.9380281094423275 \t error= 80.72164986551422 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 13 \t time= 2.240915668010712 min \t lr= 0.125 \t loss= 1.935679101452385 \t error= 81.07216536384267 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 14 \t time= 2.417655551433563 min \t lr= 0.0625 \t loss= 1.9354584057306505 \t error= 80.86597987057007 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 15 \t time= 2.5941766023635866 min \t lr= 0.0625 \t loss= 1.9353706566328854 \t error= 80.88659828471154 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 16 \t time= 2.7713255127271017 min \t lr= 0.0625 \t loss= 1.934105093946162 \t error= 80.72164980406615 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 17 \t time= 2.9497241775194802 min \t lr= 0.0625 \t loss= 1.9354609214153486 \t error= 80.84536108774009 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 18 \t time= 3.124914840857188 min \t lr= 0.03125 \t loss= 1.9333565874198049 \t error= 80.59793845894411 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 19 \t time= 3.2999334295590717 min \t lr= 0.03125 \t loss= 1.9339006303511943 \t error= 80.7628869395895 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 20 \t time= 3.473918588956197 min \t lr= 0.03125 \t loss= 1.9334246055367066 \t error= 80.61855736467027 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 21 \t time= 3.64662561416626 min \t lr= 0.03125 \t loss= 1.9338537528342807 \t error= 80.72164974261806 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 22 \t time= 3.8229596773783365 min \t lr= 0.03125 \t loss= 1.9331823759472246 \t error= 80.72164980406615 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 23 \t time= 3.997994593779246 min \t lr= 0.03125 \t loss= 1.933456720765104 \t error= 80.76288669379717 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 24 \t time= 4.1756946961085 min \t lr= 0.03125 \t loss= 1.933597670387976 \t error= 80.68041266854277 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 25 \t time= 4.348475130399068 min \t lr= 0.03125 \t loss= 1.933074492769143 \t error= 80.78350541517906 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 26 \t time= 4.522015007336934 min \t lr= 0.03125 \t loss= 1.9337960665987939 \t error= 80.72165011130657 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 27 \t time= 4.694840693473816 min \t lr= 0.03125 \t loss= 1.933499466512621 \t error= 80.7835057838676 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 28 \t time= 4.867517558733622 min \t lr= 0.03125 \t loss= 1.9338408819178945 \t error= 80.72164986551422 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 29 \t time= 5.042272222042084 min \t lr= 0.03125 \t loss= 1.9332444360575725 \t error= 80.74226840255186 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 30 \t time= 5.216053132216135 min \t lr= 0.03125 \t loss= 1.9324700709470768 \t error= 80.65979443874556 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 31 \t time= 5.394228251775106 min \t lr= 0.03125 \t loss= 1.9331636723783827 \t error= 80.7628870010376 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 32 \t time= 5.568822193145752 min \t lr= 0.03125 \t loss= 1.9318263702785845 \t error= 80.88659822326345 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 33 \t time= 5.746372028191884 min \t lr= 0.03125 \t loss= 1.9328004134070014 \t error= 80.72164961972189 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 34 \t time= 5.925148673852285 min \t lr= 0.03125 \t loss= 1.9321314932144795 \t error= 80.68041279143894 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 35 \t time= 6.099864093462626 min \t lr= 0.03125 \t loss= 1.9323341072220164 \t error= 80.6804129757832 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 36 \t time= 6.278474577267965 min \t lr= 0.03125 \t loss= 1.9321695836548953 \t error= 80.74226846399995 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 37 \t time= 6.456819224357605 min \t lr= 0.03125 \t loss= 1.931684609540959 \t error= 80.74226827965569 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 38 \t time= 6.631294409434001 min \t lr= 0.03125 \t loss= 1.9315227663394101 \t error= 80.70103132847657 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 39 \t time= 6.807824726899465 min \t lr= 0.03125 \t loss= 1.9305703529377574 \t error= 80.68041291433511 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 40 \t time= 6.982254707813263 min \t lr= 0.03125 \t loss= 1.9306694281469916 \t error= 80.76288718538186 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 41 \t time= 7.15846688747406 min \t lr= 0.03125 \t loss= 1.9305209167224844 \t error= 80.61855699598175 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 42 \t time= 7.335222633679708 min \t lr= 0.03125 \t loss= 1.9297040049562748 \t error= 80.65979388571277 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 43 \t time= 7.516233233610789 min \t lr= 0.03125 \t loss= 1.9291154760675333 \t error= 80.82474298083905 percent\n",
      "error rate on test set = 78.78409136425365 percent\n",
      " \n",
      "epoch= 44 \t time= 7.693091396490733 min \t lr= 0.03125 \t loss= 1.9286762549705112 \t error= 80.90721682174919 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 45 \t time= 7.872366841634115 min \t lr= 0.03125 \t loss= 1.9283212914909285 \t error= 81.03092822831931 percent\n",
      "error rate on test set = 80.34090995788574 percent\n",
      " \n",
      "epoch= 46 \t time= 8.052373627821604 min \t lr= 0.03125 \t loss= 1.9283142175871073 \t error= 80.7835052308348 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 47 \t time= 8.231864587465923 min \t lr= 0.03125 \t loss= 1.927083798290528 \t error= 80.96907230996594 percent\n",
      "error rate on test set = 81.27272725105286 percent\n",
      " \n",
      "epoch= 48 \t time= 8.410572278499604 min \t lr= 0.03125 \t loss= 1.9270825238571954 \t error= 80.57731998335454 percent\n",
      "error rate on test set = 80.36363666707818 percent\n",
      " \n",
      "epoch= 49 \t time= 8.588834790388743 min \t lr= 0.03125 \t loss= 1.9266707626814694 \t error= 80.5567010161803 percent\n",
      "error rate on test set = 81.42045519568704 percent\n",
      " \n",
      "epoch= 50 \t time= 8.765416300296783 min \t lr= 0.03125 \t loss= 1.9254771151493506 \t error= 80.37113473587429 percent\n",
      "error rate on test set = 80.54545467550103 percent\n",
      " \n",
      "epoch= 51 \t time= 8.940456978480022 min \t lr= 0.03125 \t loss= 1.9262704787795077 \t error= 80.41237168705341 percent\n",
      "error rate on test set = 80.00000010837208 percent\n",
      " \n",
      "epoch= 52 \t time= 9.115635633468628 min \t lr= 0.03125 \t loss= 1.9256724918011539 \t error= 80.43299053133148 percent\n",
      "error rate on test set = 80.36363666707818 percent\n",
      " \n",
      "epoch= 53 \t time= 9.29198434750239 min \t lr= 0.03125 \t loss= 1.924069271874182 \t error= 80.20618582509228 percent\n",
      "error rate on test set = 80.72727268392389 percent\n",
      " \n",
      "epoch= 54 \t time= 9.469819704691568 min \t lr= 0.03125 \t loss= 1.9250711141173373 \t error= 80.72164986551422 percent\n",
      "error rate on test set = 78.96590991453691 percent\n",
      " \n",
      "epoch= 55 \t time= 9.646781889597575 min \t lr= 0.03125 \t loss= 1.924684528223018 \t error= 80.39175302711958 percent\n",
      "error rate on test set = 80.18181865865533 percent\n",
      " \n",
      "epoch= 56 \t time= 9.818519230683645 min \t lr= 0.03125 \t loss= 1.922123085592211 \t error= 80.51546455658588 percent\n",
      "error rate on test set = 82.53409103913741 percent\n",
      " \n",
      "epoch= 57 \t time= 9.994798036416372 min \t lr= 0.03125 \t loss= 1.9245953301793521 \t error= 80.41237174850149 percent\n",
      "error rate on test set = 80.3636372089386 percent\n",
      " \n",
      "epoch= 58 \t time= 10.17326216697693 min \t lr= 0.03125 \t loss= 1.924194750097609 \t error= 80.30927881752092 percent\n",
      "error rate on test set = 80.36363666707818 percent\n",
      " \n",
      "epoch= 59 \t time= 10.350094270706176 min \t lr= 0.03125 \t loss= 1.9218135936973022 \t error= 80.63917541012322 percent\n",
      "error rate on test set = 80.36363666707818 percent\n",
      " \n",
      "epoch= 60 \t time= 10.52813852628072 min \t lr= 0.03125 \t loss= 1.9237263817148111 \t error= 80.18556777963933 percent\n",
      "error rate on test set = 81.27272833477367 percent\n",
      " \n",
      "epoch= 61 \t time= 10.707688291867575 min \t lr= 0.03125 \t loss= 1.9211648665752608 \t error= 80.7010312055804 percent\n",
      "error rate on test set = 80.90909177606757 percent\n",
      " \n",
      "epoch= 62 \t time= 10.882754596074422 min \t lr= 0.03125 \t loss= 1.9191700060343004 \t error= 80.28866003469093 percent\n",
      "error rate on test set = 80.87500008669767 percent\n",
      " \n",
      "epoch= 63 \t time= 11.061437344551086 min \t lr= 0.03125 \t loss= 1.9176191828914524 \t error= 80.536082724935 percent\n",
      "error rate on test set = 78.94318212162365 percent\n",
      " \n",
      "epoch= 64 \t time= 11.238350172837576 min \t lr= 0.03125 \t loss= 1.9183925070713477 \t error= 80.47422754395869 percent\n",
      "error rate on test set = 81.27272833477367 percent\n",
      " \n",
      "epoch= 65 \t time= 11.416601876417795 min \t lr= 0.03125 \t loss= 1.9151203730671675 \t error= 80.16494899680934 percent\n",
      "error rate on test set = 78.840909762816 percent\n",
      " \n",
      "epoch= 66 \t time= 11.591730435689291 min \t lr= 0.03125 \t loss= 1.9128205665608042 \t error= 79.27835110536556 percent\n",
      "error rate on test set = 78.8409092209556 percent\n",
      " \n",
      "epoch= 67 \t time= 11.771473681926727 min \t lr= 0.03125 \t loss= 1.9114611124254994 \t error= 79.91752630656528 percent\n",
      "error rate on test set = 83.20454521612687 percent\n",
      " \n",
      "epoch= 68 \t time= 11.949623115857442 min \t lr= 0.03125 \t loss= 1.9079344260323907 \t error= 78.59793852285011 percent\n",
      "error rate on test set = 75.6363646550612 percent\n",
      " \n",
      "epoch= 69 \t time= 12.12688516775767 min \t lr= 0.03125 \t loss= 1.9037490493243503 \t error= 78.45360851779427 percent\n",
      "error rate on test set = 79.40909103913741 percent\n",
      " \n",
      "epoch= 70 \t time= 12.303053053220113 min \t lr= 0.03125 \t loss= 1.9007866542363905 \t error= 78.35051564826179 percent\n",
      "error rate on test set = 77.27272781458768 percent\n",
      " \n",
      "epoch= 71 \t time= 12.481492133935292 min \t lr= 0.03125 \t loss= 1.894291297676637 \t error= 77.56701074924666 percent\n",
      "error rate on test set = 74.59090893918817 percent\n",
      " \n",
      "epoch= 72 \t time= 12.658549745877584 min \t lr= 0.03125 \t loss= 1.8888031821889975 \t error= 77.71134100009486 percent\n",
      "error rate on test set = 77.93181863698092 percent\n",
      " \n",
      "epoch= 73 \t time= 12.83618403673172 min \t lr= 0.03125 \t loss= 1.882814152953551 \t error= 77.25773269368202 percent\n",
      "error rate on test set = 74.87500039013949 percent\n",
      " \n",
      "epoch= 74 \t time= 13.010806028048197 min \t lr= 0.03125 \t loss= 1.874278192667617 \t error= 76.74226865326006 percent\n",
      "error rate on test set = 76.63636370138688 percent\n",
      " \n",
      "epoch= 75 \t time= 13.188963953653971 min \t lr= 0.03125 \t loss= 1.866927361979927 \t error= 75.50515514059165 percent\n",
      "error rate on test set = 75.2727291800759 percent\n",
      " \n",
      "epoch= 76 \t time= 13.36552426815033 min \t lr= 0.03125 \t loss= 1.8590018306810832 \t error= 75.5051548947993 percent\n",
      "error rate on test set = 75.43181722814386 percent\n",
      " \n",
      "epoch= 77 \t time= 13.541527318954468 min \t lr= 0.03125 \t loss= 1.851847992729895 \t error= 75.38144422560623 percent\n",
      "error rate on test set = 73.82954521612687 percent\n",
      " \n",
      "epoch= 78 \t time= 13.71840888261795 min \t lr= 0.03125 \t loss= 1.8453527000761523 \t error= 74.76288749999607 percent\n",
      "error rate on test set = 74.50000101869757 percent\n",
      " \n",
      "epoch= 79 \t time= 13.8940753976504 min \t lr= 0.03125 \t loss= 1.82710237109784 \t error= 73.6701035622469 percent\n",
      "error rate on test set = 72.31818275018172 percent\n",
      " \n",
      "epoch= 80 \t time= 14.070192631085714 min \t lr= 0.03125 \t loss= 1.8234127944277734 \t error= 73.5876295369925 percent\n",
      "error rate on test set = 70.96590941602533 percent\n",
      " \n",
      "epoch= 81 \t time= 14.246747867266338 min \t lr= 0.03125 \t loss= 1.813999544713915 \t error= 73.13402098478731 percent\n",
      "error rate on test set = 72.67045432871039 percent\n",
      " \n",
      "epoch= 82 \t time= 14.424071725209554 min \t lr= 0.03125 \t loss= 1.809770230165462 \t error= 72.72164993679401 percent\n",
      "error rate on test set = 72.36363671042703 percent\n",
      " \n",
      "epoch= 83 \t time= 14.601392467816671 min \t lr= 0.03125 \t loss= 1.8010903940987342 \t error= 71.95876326757607 percent\n",
      "error rate on test set = 77.87499969655816 percent\n",
      " \n",
      "epoch= 84 \t time= 14.778580824534098 min \t lr= 0.03125 \t loss= 1.7944030380740608 \t error= 71.62886704366231 percent\n",
      "error rate on test set = 72.69318212162365 percent\n",
      " \n",
      "epoch= 85 \t time= 14.958258966604868 min \t lr= 0.03125 \t loss= 1.7819800167968594 \t error= 72.14433034670722 percent\n",
      "error rate on test set = 70.52272829142484 percent\n",
      " \n",
      "epoch= 86 \t time= 15.13366725842158 min \t lr= 0.03125 \t loss= 1.7696769372704102 \t error= 70.61855706971946 percent\n",
      "error rate on test set = 69.43181807344611 percent\n",
      " \n",
      "epoch= 87 \t time= 15.310980939865113 min \t lr= 0.03125 \t loss= 1.7679413901161902 \t error= 70.49484615473403 percent\n",
      "error rate on test set = 67.75000149553473 percent\n",
      " \n",
      "epoch= 88 \t time= 15.48768751223882 min \t lr= 0.03125 \t loss= 1.7560765792414086 \t error= 69.25773245772136 percent\n",
      "error rate on test set = 68.84091008793224 percent\n",
      " \n",
      "epoch= 89 \t time= 15.665140469868978 min \t lr= 0.03125 \t loss= 1.7470463207087565 \t error= 68.41237207048947 percent\n",
      "error rate on test set = 66.97727225043558 percent\n",
      " \n",
      "epoch= 90 \t time= 15.844214777151743 min \t lr= 0.03125 \t loss= 1.7440099175443355 \t error= 69.56701137355923 percent\n",
      "error rate on test set = 68.76136389645663 percent\n",
      " \n",
      "epoch= 91 \t time= 16.021840206782024 min \t lr= 0.03125 \t loss= 1.7286820915556445 \t error= 67.6288663726492 percent\n",
      "error rate on test set = 68.39772733775052 percent\n",
      " \n",
      "epoch= 92 \t time= 16.199610658486684 min \t lr= 0.03125 \t loss= 1.7200388650304264 \t error= 68.10309358478821 percent\n",
      "error rate on test set = 68.92045465382662 percent\n",
      " \n",
      "epoch= 93 \t time= 16.376054108142853 min \t lr= 0.03125 \t loss= 1.717399487790373 \t error= 68.12371230617012 percent\n",
      "error rate on test set = 66.81818203492598 percent\n",
      " \n",
      "epoch= 94 \t time= 16.555346175034842 min \t lr= 0.03125 \t loss= 1.7053552398976592 \t error= 66.35051615459403 percent\n",
      "error rate on test set = 68.81818121129815 percent\n",
      " \n",
      "epoch= 95 \t time= 16.731302392482757 min \t lr= 0.03125 \t loss= 1.7041543009354896 \t error= 66.61855725897956 percent\n",
      "error rate on test set = 70.06818110292609 percent\n",
      " \n",
      "epoch= 96 \t time= 16.90601748228073 min \t lr= 0.03125 \t loss= 1.6897016493315549 \t error= 66.49484603675371 percent\n",
      "error rate on test set = 65.56818214329806 percent\n",
      " \n",
      "epoch= 97 \t time= 17.077899940808614 min \t lr= 0.03125 \t loss= 1.6860563189712996 \t error= 66.10309371014232 percent\n",
      "error rate on test set = 64.17045593261719 percent\n",
      " \n",
      "epoch= 98 \t time= 17.256335520744322 min \t lr= 0.03125 \t loss= 1.6737131568574415 \t error= 66.12371144835481 percent\n",
      "error rate on test set = 65.52272818305276 percent\n",
      " \n",
      "epoch= 99 \t time= 17.431722315152488 min \t lr= 0.03125 \t loss= 1.6704940992532318 \t error= 64.74226879090378 percent\n",
      "error rate on test set = 64.84090956774625 percent\n",
      " \n",
      "epoch= 100 \t time= 17.60707573890686 min \t lr= 0.03125 \t loss= 1.6573482567502051 \t error= 64.84536153754009 percent\n",
      "error rate on test set = 65.69318175315857 percent\n",
      " \n",
      "epoch= 101 \t time= 17.78621589342753 min \t lr= 0.03125 \t loss= 1.6563971091791527 \t error= 64.26804176310903 percent\n",
      "error rate on test set = 66.81818203492598 percent\n",
      " \n",
      "epoch= 102 \t time= 17.96485393444697 min \t lr= 0.03125 \t loss= 1.6398389597528988 \t error= 63.95876383044056 percent\n",
      "error rate on test set = 63.102274049412124 percent\n",
      " \n",
      "epoch= 103 \t time= 18.143370882670084 min \t lr= 0.03125 \t loss= 1.6265936475439169 \t error= 64.12371231108597 percent\n",
      "error rate on test set = 67.25000143051147 percent\n",
      " \n",
      "epoch= 104 \t time= 18.325059747695924 min \t lr= 0.03125 \t loss= 1.6245437553248454 \t error= 62.41237213931132 percent\n",
      "error rate on test set = 65.45454588803378 percent\n",
      " \n",
      "epoch= 105 \t time= 18.504397650559742 min \t lr= 0.03125 \t loss= 1.6191659686491662 \t error= 63.17525880852926 percent\n",
      "error rate on test set = 63.40909220955589 percent\n",
      " \n",
      "epoch= 106 \t time= 18.682694307963054 min \t lr= 0.03125 \t loss= 1.6182316738305633 \t error= 62.90721684387049 percent\n",
      "error rate on test set = 63.26136318120089 percent\n",
      " \n",
      "epoch= 107 \t time= 18.86254997253418 min \t lr= 0.03125 \t loss= 1.6001763687920325 \t error= 61.85567053322939 percent\n",
      "error rate on test set = 60.78409173271873 percent\n",
      " \n",
      "epoch= 108 \t time= 19.038921312491098 min \t lr= 0.03125 \t loss= 1.5960503841183848 \t error= 62.22680487583593 percent\n",
      "error rate on test set = 62.522727251052856 percent\n",
      " \n",
      "epoch= 109 \t time= 19.214438927173614 min \t lr= 0.03125 \t loss= 1.5960629404205637 \t error= 62.26804164267078 percent\n",
      "error rate on test set = 61.443182555111974 percent\n",
      " \n",
      "epoch= 110 \t time= 19.391205640633903 min \t lr= 0.03125 \t loss= 1.5777382346772657 \t error= 61.58762967463621 percent\n",
      "error rate on test set = 61.93181818181818 percent\n",
      " \n",
      "epoch= 111 \t time= 19.56958175500234 min \t lr= 0.03125 \t loss= 1.5741824440120422 \t error= 60.185567619874305 percent\n",
      "error rate on test set = 60.863637924194336 percent\n",
      " \n",
      "epoch= 112 \t time= 19.749676541487375 min \t lr= 0.03125 \t loss= 1.5609235898735596 \t error= 60.90721752225738 percent\n",
      "error rate on test set = 61.96591041304848 percent\n",
      " \n",
      "epoch= 113 \t time= 19.928732148806255 min \t lr= 0.03125 \t loss= 1.554122986252775 \t error= 60.18556774277049 percent\n",
      "error rate on test set = 62.340909784490414 percent\n",
      " \n",
      "epoch= 114 \t time= 20.106204982598623 min \t lr= 0.03125 \t loss= 1.5510159288485026 \t error= 60.02061956936551 percent\n",
      "error rate on test set = 59.465909546071835 percent\n",
      " \n",
      "epoch= 115 \t time= 20.285120936234794 min \t lr= 0.03125 \t loss= 1.5349998904257705 \t error= 59.587629738542226 percent\n",
      "error rate on test set = 61.55681935223666 percent\n",
      " \n",
      "epoch= 116 \t time= 20.46657478014628 min \t lr= 0.03125 \t loss= 1.5348699203471547 \t error= 59.09278441950217 percent\n",
      "error rate on test set = 59.26136374473572 percent\n",
      " \n",
      "epoch= 117 \t time= 20.643152252833048 min \t lr= 0.03125 \t loss= 1.525413028972665 \t error= 58.51546446072686 percent\n",
      "error rate on test set = 59.30681933056224 percent\n",
      " \n",
      "epoch= 118 \t time= 20.824201154708863 min \t lr= 0.03125 \t loss= 1.5235372327037693 \t error= 58.329897565939994 percent\n",
      "error rate on test set = 59.75000045516274 percent\n",
      " \n",
      "epoch= 119 \t time= 21.00303211212158 min \t lr= 0.03125 \t loss= 1.5071762517555474 \t error= 57.91752657939478 percent\n",
      "error rate on test set = 57.90909095243975 percent\n",
      " \n",
      "epoch= 120 \t time= 21.183395993709563 min \t lr= 0.03125 \t loss= 1.4991720546152174 \t error= 57.505155592849576 percent\n",
      "error rate on test set = 61.90909093076532 percent\n",
      " \n",
      "epoch= 121 \t time= 21.36128970781962 min \t lr= 0.03125 \t loss= 1.4955006174205505 \t error= 56.86598045309794 percent\n",
      "error rate on test set = 67.98863627693869 percent\n",
      " \n",
      "epoch= 122 \t time= 21.540926420688628 min \t lr= 0.03125 \t loss= 1.4762027079297095 \t error= 56.5154648933214 percent\n",
      "error rate on test set = 57.625001668930054 percent\n",
      " \n",
      "epoch= 123 \t time= 21.718884805838268 min \t lr= 0.03125 \t loss= 1.47628088464442 \t error= 56.5154648933214 percent\n",
      "error rate on test set = 56.25000108372081 percent\n",
      " \n",
      "epoch= 124 \t time= 21.900348587830862 min \t lr= 0.03125 \t loss= 1.462811997256328 \t error= 55.83505280239066 percent\n",
      "error rate on test set = 56.86363632028753 percent\n",
      " \n",
      "epoch= 125 \t time= 22.081785555680593 min \t lr= 0.03125 \t loss= 1.4551054448196568 \t error= 55.23711418368153 percent\n",
      "error rate on test set = 55.82954612645236 percent\n",
      " \n",
      "epoch= 126 \t time= 22.26220999956131 min \t lr= 0.03125 \t loss= 1.437827525679598 \t error= 54.474227698807866 percent\n",
      "error rate on test set = 56.17045651782643 percent\n",
      " \n",
      "epoch= 127 \t time= 22.445402491092683 min \t lr= 0.03125 \t loss= 1.4264066231619452 \t error= 54.12371244627175 percent\n",
      "error rate on test set = 58.000000498511575 percent\n",
      " \n",
      "epoch= 128 \t time= 22.626028382778166 min \t lr= 0.03125 \t loss= 1.4251857430664534 \t error= 53.60824834440172 percent\n",
      "error rate on test set = 71.8295460397547 percent\n",
      " \n",
      "epoch= 129 \t time= 22.804371778170268 min \t lr= 0.03125 \t loss= 1.4144208197741164 \t error= 54.020619822531636 percent\n",
      "error rate on test set = 59.44318229501898 percent\n",
      " \n",
      "epoch= 130 \t time= 22.98585546016693 min \t lr= 0.03125 \t loss= 1.3980921396275157 \t error= 52.90721765498525 percent\n",
      "error rate on test set = 54.556818983771585 percent\n",
      " \n",
      "epoch= 131 \t time= 23.166493582725526 min \t lr= 0.03125 \t loss= 1.3972337147624223 \t error= 52.22680531826216 percent\n",
      "error rate on test set = 63.53409127755598 percent\n",
      " \n",
      "epoch= 132 \t time= 23.348709197839103 min \t lr= 0.03125 \t loss= 1.3872978257149766 \t error= 51.979382197881485 percent\n",
      "error rate on test set = 59.69318368218162 percent\n",
      " \n",
      "epoch= 133 \t time= 23.53088131348292 min \t lr= 0.03125 \t loss= 1.3770400519223558 \t error= 51.75257798322698 percent\n",
      "error rate on test set = 58.079546148126774 percent\n",
      " \n",
      "epoch= 134 \t time= 23.712230249245962 min \t lr= 0.03125 \t loss= 1.3634856066752954 \t error= 51.505156030359956 percent\n",
      "error rate on test set = 58.03409164602106 percent\n",
      " \n",
      "epoch= 135 \t time= 23.8918474038442 min \t lr= 0.03125 \t loss= 1.363784933827587 \t error= 51.587630055614355 percent\n",
      "error rate on test set = 59.26136428659613 percent\n",
      " \n",
      "epoch= 136 \t time= 24.07425004641215 min \t lr= 0.03125 \t loss= 1.342142212022211 \t error= 50.49484636365753 percent\n",
      "error rate on test set = 54.943182251670144 percent\n",
      " \n",
      "epoch= 137 \t time= 24.254772222042085 min \t lr= 0.03125 \t loss= 1.342406909490369 \t error= 50.53608362207708 percent\n",
      "error rate on test set = 56.31818229501898 percent\n",
      " \n",
      "epoch= 138 \t time= 24.43941377401352 min \t lr= 0.03125 \t loss= 1.3283902898277204 \t error= 49.64948560773712 percent\n",
      "error rate on test set = 56.77272785793651 percent\n",
      " \n",
      "epoch= 139 \t time= 24.620780758063 min \t lr= 0.03125 \t loss= 1.3188740383718431 \t error= 50.41237239985122 percent\n",
      "error rate on test set = 52.784092317927964 percent\n",
      " \n",
      "epoch= 140 \t time= 24.80235030253728 min \t lr= 0.03125 \t loss= 1.2977033411104655 \t error= 47.958764218792474 percent\n",
      "error rate on test set = 54.23863638531078 percent\n",
      " \n",
      "epoch= 141 \t time= 24.98376611073812 min \t lr= 0.03125 \t loss= 1.2802718933095638 \t error= 47.917527267613366 percent\n",
      "error rate on test set = 59.715910391374074 percent\n",
      " \n",
      "epoch= 142 \t time= 25.166232967376708 min \t lr= 0.03125 \t loss= 1.2832554443595336 \t error= 48.9072176599011 percent\n",
      "error rate on test set = 53.89772870323875 percent\n",
      " \n",
      "epoch= 143 \t time= 25.346542223294577 min \t lr= 0.03125 \t loss= 1.2543523870792586 \t error= 47.19587761102264 percent\n",
      "error rate on test set = 54.863636602054946 percent\n",
      " \n",
      "epoch= 144 \t time= 25.52553403377533 min \t lr= 0.03125 \t loss= 1.2374049511152445 \t error= 46.20618697294255 percent\n",
      "error rate on test set = 53.85227311741222 percent\n",
      " \n",
      "epoch= 145 \t time= 25.70286262432734 min \t lr= 0.03125 \t loss= 1.24393909862361 \t error= 46.474228077328085 percent\n",
      "error rate on test set = 54.84091097658331 percent\n",
      " \n",
      "epoch= 146 \t time= 25.88683128754298 min \t lr= 0.03125 \t loss= 1.2202225352070994 \t error= 45.3195893887392 percent\n",
      "error rate on test set = 59.50000177730214 percent\n",
      " \n",
      "epoch= 147 \t time= 26.07148285706838 min \t lr= 0.03125 \t loss= 1.2059513361183638 \t error= 44.288661369343394 percent\n",
      "error rate on test set = 53.48863818428733 percent\n",
      " \n",
      "epoch= 148 \t time= 26.254608527819315 min \t lr= 0.03125 \t loss= 1.1859051984610016 \t error= 43.97938300653831 percent\n",
      "error rate on test set = 55.522727966308594 percent\n",
      " \n",
      "epoch= 149 \t time= 26.435846904913586 min \t lr= 0.03125 \t loss= 1.1843089860739167 \t error= 43.56701183564884 percent\n",
      "error rate on test set = 53.25000015172091 percent\n",
      " \n",
      "epoch= 150 \t time= 26.618368224302927 min \t lr= 0.03125 \t loss= 1.1707760968159155 \t error= 43.38144469506962 percent\n",
      "error rate on test set = 59.840910543094985 percent\n",
      " \n",
      "epoch= 151 \t time= 26.799894857406617 min \t lr= 0.03125 \t loss= 1.148601975637613 \t error= 41.958764164718154 percent\n",
      "error rate on test set = 53.02272764119235 percent\n",
      " \n",
      "epoch= 152 \t time= 26.980521380901337 min \t lr= 0.03125 \t loss= 1.1365962778170084 \t error= 42.824743703468556 percent\n",
      "error rate on test set = 56.80681846358559 percent\n",
      " \n",
      "epoch= 153 \t time= 27.161717275778454 min \t lr= 0.03125 \t loss= 1.1192227300909376 \t error= 41.52577494837574 percent\n",
      "error rate on test set = 56.022728573192246 percent\n",
      " \n",
      "epoch= 154 \t time= 27.341721359888712 min \t lr= 0.03125 \t loss= 1.1152837313327593 \t error= 41.40206335746136 percent\n",
      "error rate on test set = 58.829546516591854 percent\n",
      " \n",
      "epoch= 155 \t time= 27.520644994576774 min \t lr= 0.03125 \t loss= 1.0671975391427266 \t error= 39.54639336497514 percent\n",
      "error rate on test set = 59.88636396147988 percent\n",
      " \n",
      "epoch= 156 \t time= 27.698707679907482 min \t lr= 0.03125 \t loss= 1.0921148590205871 \t error= 40.00000148704371 percent\n",
      "error rate on test set = 53.590910543094985 percent\n",
      " \n",
      "epoch= 157 \t time= 27.877548937002818 min \t lr= 0.03125 \t loss= 1.044615392832412 \t error= 38.47422777991934 percent\n",
      "error rate on test set = 55.897727879610926 percent\n",
      " \n",
      "epoch= 158 \t time= 28.058466629187265 min \t lr= 0.03125 \t loss= 1.034455500927168 \t error= 38.28866131526908 percent\n",
      "error rate on test set = 52.579546516591854 percent\n",
      " \n",
      "epoch= 159 \t time= 28.240092074871065 min \t lr= 0.03125 \t loss= 1.0101730252049632 \t error= 36.1237128370816 percent\n",
      "error rate on test set = 54.045456106012516 percent\n",
      " \n",
      "epoch= 160 \t time= 28.419613925615945 min \t lr= 0.03125 \t loss= 1.0014362544128574 \t error= 37.25773341876945 percent\n",
      "error rate on test set = 56.62500099702314 percent\n",
      " \n",
      "epoch= 161 \t time= 28.60061534643173 min \t lr= 0.03125 \t loss= 0.9833575179896403 \t error= 36.55670248356062 percent\n",
      "error rate on test set = 56.36363788084551 percent\n",
      " \n",
      "epoch= 162 \t time= 28.783534971872964 min \t lr= 0.03125 \t loss= 0.9665578450124288 \t error= 35.42268184042469 percent\n",
      "error rate on test set = 60.84091013128107 percent\n",
      " \n",
      "epoch= 163 \t time= 28.96589869260788 min \t lr= 0.03125 \t loss= 0.9481477915626211 \t error= 33.979383080276016 percent\n",
      "error rate on test set = 57.31818296692588 percent\n",
      " \n",
      "epoch= 164 \t time= 29.148845279216765 min \t lr= 0.03125 \t loss= 0.9186499641113675 \t error= 33.23711476375147 percent\n",
      "error rate on test set = 52.53409255634654 percent\n",
      " \n",
      "epoch= 165 \t time= 29.32970544497172 min \t lr= 0.03125 \t loss= 0.8996290005359453 \t error= 32.72165078477761 percent\n",
      "error rate on test set = 54.681819677352905 percent\n",
      " \n",
      "epoch= 166 \t time= 29.511141296227773 min \t lr= 0.03125 \t loss= 0.8884018481392222 \t error= 32.82474383865435 percent\n",
      "error rate on test set = 57.57954608310353 percent\n",
      " \n",
      "epoch= 167 \t time= 29.690944159030913 min \t lr= 0.03125 \t loss= 0.8646120072640094 \t error= 31.134022203917354 percent\n",
      "error rate on test set = 58.28409194946289 percent\n",
      " \n",
      "epoch= 168 \t time= 29.872451515992484 min \t lr= 0.03125 \t loss= 0.8458032162533593 \t error= 30.78350676703699 percent\n",
      "error rate on test set = 56.94318251176313 percent\n",
      " \n",
      "epoch= 169 \t time= 30.055125228563945 min \t lr= 0.03125 \t loss= 0.8241012120984265 \t error= 30.412372670222805 percent\n",
      "error rate on test set = 58.193181861530654 percent\n",
      " \n",
      "epoch= 170 \t time= 30.236460117499032 min \t lr= 0.03125 \t loss= 0.8057367958358883 \t error= 29.38144477372317 percent\n",
      "error rate on test set = 56.39772794463418 percent\n",
      " \n",
      "epoch= 171 \t time= 30.41769819657008 min \t lr= 0.03125 \t loss= 0.754930173306121 \t error= 27.21649666422421 percent\n",
      "error rate on test set = 54.056818376887925 percent\n",
      " \n",
      "epoch= 172 \t time= 30.599030462900796 min \t lr= 0.03125 \t loss= 0.774222117109397 \t error= 28.16495004388475 percent\n",
      "error rate on test set = 55.715909871188074 percent\n",
      " \n",
      "epoch= 173 \t time= 30.779565199216208 min \t lr= 0.03125 \t loss= 0.7386085858050081 \t error= 26.391754260997182 percent\n",
      "error rate on test set = 56.272727792913265 percent\n",
      " \n",
      "epoch= 174 \t time= 30.959615727265675 min \t lr= 0.03125 \t loss= 0.7129860544942089 \t error= 25.422682221402827 percent\n",
      "error rate on test set = 59.68182032758539 percent\n",
      " \n",
      "epoch= 175 \t time= 31.14078207015991 min \t lr= 0.03125 \t loss= 0.7021253511463244 \t error= 24.86598092256133 percent\n",
      "error rate on test set = 56.00000132213939 percent\n",
      " \n",
      "epoch= 176 \t time= 31.321414399147034 min \t lr= 0.03125 \t loss= 0.6463498033813595 \t error= 22.783507207005293 percent\n",
      "error rate on test set = 52.2386372089386 percent\n",
      " \n",
      "epoch= 177 \t time= 31.500292321046192 min \t lr= 0.03125 \t loss= 0.6667474514430332 \t error= 23.25773411190387 percent\n",
      "error rate on test set = 56.93181915716692 percent\n",
      " \n",
      "epoch= 178 \t time= 31.68141573270162 min \t lr= 0.03125 \t loss= 0.6347600581105223 \t error= 23.154641242371394 percent\n",
      "error rate on test set = 54.78409257802096 percent\n",
      " \n",
      "epoch= 179 \t time= 31.861907855669656 min \t lr= 0.03125 \t loss= 0.6136405999513016 \t error= 22.494847196893595 percent\n",
      "error rate on test set = 54.45454608310353 percent\n",
      " \n",
      "epoch= 180 \t time= 32.04051053126653 min \t lr= 0.03125 \t loss= 0.6003424270251363 \t error= 21.670105531043614 percent\n",
      "error rate on test set = 54.84090989286249 percent\n",
      " \n",
      "epoch= 181 \t time= 32.21925246318181 min \t lr= 0.03125 \t loss= 0.5597557735811803 \t error= 19.319589973724995 percent\n",
      "error rate on test set = 54.21591021797874 percent\n",
      " \n",
      "epoch= 182 \t time= 32.3971392472585 min \t lr= 0.03125 \t loss= 0.5568465304743383 \t error= 20.18556914378687 percent\n",
      "error rate on test set = 53.69318181818182 percent\n",
      " \n",
      "epoch= 183 \t time= 32.57758649190267 min \t lr= 0.03125 \t loss= 0.5548309812840727 \t error= 19.567012295280538 percent\n",
      "error rate on test set = 55.40909171104431 percent\n",
      " \n",
      "epoch= 184 \t time= 32.75879933436712 min \t lr= 0.03125 \t loss= 0.5100639837304342 \t error= 18.185569637829495 percent\n",
      "error rate on test set = 55.76136437329379 percent\n",
      " \n",
      "epoch= 185 \t time= 32.93805969953537 min \t lr= 0.03125 \t loss= 0.47944237768035575 \t error= 16.804126058657147 percent\n",
      "error rate on test set = 53.59091000123457 percent\n",
      " \n",
      "epoch= 186 \t time= 33.11811887025833 min \t lr= 0.03125 \t loss= 0.49278351203682497 \t error= 17.31958991473483 percent\n",
      "error rate on test set = 59.2500009319999 percent\n",
      " \n",
      "epoch= 187 \t time= 33.29475942850113 min \t lr= 0.03125 \t loss= 0.47767319645463807 \t error= 16.721651910506573 percent\n",
      "error rate on test set = 54.818183183670044 percent\n",
      " \n",
      "epoch= 188 \t time= 33.47255133390426 min \t lr= 0.03125 \t loss= 0.42900514449040916 \t error= 15.505156811979628 percent\n",
      "error rate on test set = 52.54545536908236 percent\n",
      " \n",
      "epoch= 189 \t time= 33.64905718962351 min \t lr= 0.03125 \t loss= 0.4323474142662029 \t error= 16.04123938943922 percent\n",
      "error rate on test set = 53.38636528361928 percent\n",
      " \n",
      "epoch= 190 \t time= 33.82693765560786 min \t lr= 0.03125 \t loss= 0.4149257278012246 \t error= 13.979383780784213 percent\n",
      "error rate on test set = 54.215909676118336 percent\n",
      " \n",
      "epoch= 191 \t time= 34.00663630167643 min \t lr= 0.03125 \t loss= 0.41084856286491317 \t error= 14.659796363299654 percent\n",
      "error rate on test set = 52.4772741577842 percent\n",
      " \n",
      "epoch= 192 \t time= 34.1884383002917 min \t lr= 0.03125 \t loss= 0.3985026302104144 \t error= 14.247425008065923 percent\n",
      "error rate on test set = 56.13636374473572 percent\n",
      " \n",
      "epoch= 193 \t time= 34.36619440714518 min \t lr= 0.03125 \t loss= 0.36477531262279783 \t error= 12.536084651947021 percent\n",
      "error rate on test set = 55.193183638832785 percent\n",
      " \n",
      "epoch= 194 \t time= 34.5443258245786 min \t lr= 0.03125 \t loss= 0.35541614682711276 \t error= 12.20618793644856 percent\n",
      "error rate on test set = 54.03409112583507 percent\n",
      " \n",
      "epoch= 195 \t time= 34.720486625035605 min \t lr= 0.03125 \t loss= 0.3552047584935562 \t error= 12.474229409522616 percent\n",
      "error rate on test set = 53.95454601808027 percent\n",
      " \n",
      "epoch= 196 \t time= 34.9001341342926 min \t lr= 0.03125 \t loss= 0.34714854124587835 \t error= 12.061857869944621 percent\n",
      "error rate on test set = 56.034091385928065 percent\n",
      " \n",
      "epoch= 197 \t time= 35.079871730009714 min \t lr= 0.03125 \t loss= 0.3385397063702652 \t error= 11.15464205594407 percent\n",
      "error rate on test set = 57.95454599640586 percent\n",
      " \n",
      "epoch= 198 \t time= 35.26079976161321 min \t lr= 0.03125 \t loss= 0.31275503698390783 \t error= 10.453610874942898 percent\n",
      "error rate on test set = 55.193183638832785 percent\n",
      " \n",
      "epoch= 199 \t time= 35.44280279477437 min \t lr= 0.03125 \t loss= 0.29749437014466706 \t error= 9.814435120710392 percent\n",
      "error rate on test set = 51.59091028300199 percent\n",
      " \n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(1,200):\n",
    "    \n",
    "    # divide the learning rate by 2 at epoch 10, 14 and 18\n",
    "    if epoch==10 or epoch == 14 or epoch==18:\n",
    "        my_lr = my_lr / 2\n",
    "    \n",
    "    # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "        \n",
    "    # set the running quatities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    running_error=0\n",
    "    num_batches=0\n",
    "    \n",
    "    for minibatch_data, minibatch_label in train_dl:\n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # send them to the gpu\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        # reshape the minibatch\n",
    "        inputs = minibatch_data.view(-1, 1, 32, 32)\n",
    "\n",
    "        # tell Pytorch to start tracking all operations that will be done on \"inputs\"\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        # forward the minibatch through the net \n",
    "        scores=net( inputs ) \n",
    "\n",
    "        # Compute the average of the losses of the data points in the minibatch\n",
    "        loss =  criterion( scores , minibatch_label) \n",
    "        \n",
    "        # backward pass to compute dL/dU, dL/dV and dL/dW   \n",
    "        loss.backward()\n",
    "\n",
    "        # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # START COMPUTING STATS\n",
    "        \n",
    "        # add the loss of this batch to the running loss\n",
    "        running_loss += loss.detach().item()\n",
    "        \n",
    "        # compute the error made on this batch and add it to the running error       \n",
    "        error = utils.get_error( scores.detach() , minibatch_label)\n",
    "        running_error += error.item()\n",
    "        \n",
    "        num_batches+=1        \n",
    "    \n",
    "    \n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    total_error = running_error/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min','\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n",
    "    eval_on_test_set() \n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HdOZwqTOtoi"
   },
   "source": [
    "# VGG -- nn.MaxPool2d(4 x 4)\n",
    "The attempted improvement done over here is to increase the size of the average pooling layers from 2x2 to 4x4. This was done for multiple reasons.\n",
    "\n",
    "We do not wish to resize the input layer of 1x128x128 first because this image classification tasks deals with facial expressions and facial features which are detailed and may contain useful features for each small pixel. However, due to the size of the input layer, it results in a number of parameters in the neural network. This may result in overfitting.\n",
    "\n",
    "Hence, to reduce the number of parameters, while seeking to retain the information captured at fine-grain pixel level, we attemp to increase the size of the average pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_convnet_px128(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG_convnet, self).__init__()\n",
    "\n",
    "        # block 1:         1 x 128 x 128 --> 64 x 32 x 32\n",
    "        self.conv1a = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv1b = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(4, 4)\n",
    "\n",
    "        # block 2:         64 x 32 x 32 --> 128 x 8 x 8\n",
    "        self.conv2a = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(4, 4)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        self.linear1 = nn.Linear(2048, 4096)\n",
    "        self.linear2 = nn.Linear(4096, 4096)\n",
    "        self.linear3 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # block 1:         1 x 128 x 128 --> 64 x 64 x 64\n",
    "        x = self.conv1a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # block 2:         64 x 64 x 64 --> 128 x 16 x 16\n",
    "        x = self.conv2a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # block 3:         128 x 16 x 16 --> 256 x 4 x 4\n",
    "        x = self.conv3a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        x = self.conv4a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        x = x.view(-1, 2048)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "'''\n",
    "utils.display_num_param(net)\n",
    "\n",
    "VGG_convnet_px128(\n",
    "  (conv1a): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (conv1b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (pool1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2a): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (conv2b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (pool2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv3a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (conv3b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv4a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (linear1): Linear(in_features=2048, out_features=4096, bias=True)\n",
    "  (linear2): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "  (linear3): Linear(in_features=4096, out_features=10, bias=True)\n",
    "  There are 27539402 (27.54 million) parameters in this neural network\n",
    ")\n",
    "'''\n",
    "\n",
    "'''\n",
    "See log/vgg_px128.txt for the full output.\n",
    " \n",
    "epoch= 197 \t time= 13.116444532076518 min \t lr= 0.03125 \t loss= 0.1217539941642395 \t error= 4.123713613785419 percent\n",
    "error rate on test set = 53.06818268515847 percent\n",
    " \n",
    "epoch= 198 \t time= 13.181400994459787 min \t lr= 0.03125 \t loss= 0.10981417798734817 \t error= 3.4639196912037957 percent\n",
    "error rate on test set = 49.53409162434665 percent\n",
    " \n",
    "epoch= 199 \t time= 13.245910755793254 min \t lr= 0.03125 \t loss= 0.10294757859262917 \t error= 3.216496878063556 percent\n",
    "error rate on test set = 50.806818767027416 percent\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "We find that the error rate on the train set is much higher than the test set.\n",
    "\n",
    "In order to combat overfitting in the network, we try inserting Dropout layers after convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_convnet_dropout(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG_convnet, self).__init__()\n",
    "\n",
    "        # block 1:         1 x 128 x 128 --> 64 x 32 x 32\n",
    "        self.conv1a = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv1b = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(4, 4)\n",
    "\n",
    "        # block 2:         64 x 32 x 32 --> 128 x 8 x 8\n",
    "        self.conv2a = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(4, 4)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        self.conv4a = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        self.linear1 = nn.Linear(2048, 4096)\n",
    "        self.linear2 = nn.Linear(4096, 4096)\n",
    "        self.linear3 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # block 1:         1 x 128 x 128 --> 64 x 32 x 32\n",
    "        x = self.conv1a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # block 2:         64 x 32 x 32 --> 128 x 8 x 8\n",
    "        x = self.conv2a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # block 3:         128 x 8 x 8 --> 256 x 4 x 4\n",
    "        x = self.conv3a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # block 4:          256 x 4 x 4 --> 512 x 2 x 2\n",
    "        x = self.conv4a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # linear layers:   512 x 2 x 2 --> 2048 --> 4096 --> 4096 --> 10\n",
    "        x = x.view(-1, 2048)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "'''\n",
    "VGG_convnet(     \n",
    "  (conv1a): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (conv1b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (pool1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
    "  (drop1): Dropout(p=0.5, inplace=False)\n",
    "  (conv2a): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (conv2b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (pool2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
    "  (drop2): Dropout(p=0.5, inplace=False)\n",
    "  (conv3a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (conv3b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (drop3): Dropout(p=0.5, inplace=False)\n",
    "  (conv4a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (linear1): Linear(in_features=2048, out_features=4096, bias=True)\n",
    "  (linear2): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "  (linear3): Linear(in_features=4096, out_features=10, bias=True)\n",
    ")\n",
    "There are 27539402 (27.54 million) parameters in this neural network\n",
    "'''\n",
    "\n",
    "'''\n",
    "See log/vgg_dropout.txt for the full output.\n",
    " \n",
    "epoch= 196 \t time= 13.345274138450623 min \t lr= 0.03125 \t loss= 0.5204616894119793 \t error= 19.60824961514817 percent\n",
    "error rate on test set = 49.590908939188175 percent\n",
    " \n",
    "epoch= 197 \t time= 13.412516383330027 min \t lr= 0.03125 \t loss= 0.5394029445254925 \t error= 20.49484738369578 percent\n",
    "error rate on test set = 50.23863857442682 percent\n",
    " \n",
    "epoch= 198 \t time= 13.479526805877686 min \t lr= 0.03125 \t loss= 0.5349615907546171 \t error= 19.793816694279307 percent\n",
    "error rate on test set = 50.943182273344554 percent\n",
    " \n",
    "epoch= 199 \t time= 13.546925719579061 min \t lr= 0.03125 \t loss= 0.5200335079247189 \t error= 19.31958985082882 percent\n",
    "error rate on test set = 50.69318251176313 percent\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of Optimizer\n",
    "\n",
    "We try three optimizers:\n",
    "+ SGD\n",
    "+ SGD + Momentum\n",
    "+ Adam\n",
    "\n",
    "For fare comparision, we use the default values of learning rate, beta1 and beta2 in pytorch.\n",
    "\n",
    "\n",
    "Our observations:\n",
    "\n",
    "+ Convergence. Adaptive optimizers such as Adam give fatser convergence than SGD and Momentum SGD, but it may get stuck in a local minima somehow and provides poor generalization\n",
    "\n",
    "+ Global minima. SGD+momentum can achieve to find a global minima, but it relies on robust initializations and it might take longer than Adam to converge\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "'''\n",
    "See log/vgg_optimizer_sgd.txt for the full output.\n",
    "\n",
    "epoch= 197 \t time= 16.640492721398672 min \t loss= 1.4266390739027988 \t error= 55.340207421902534 percent\n",
    "error rate on test set = 58.886363831433385 percent\n",
    "epoch= 198 \t time= 16.727175052960714 min \t loss= 1.4200772022463612 \t error= 54.90721771397542 percent\n",
    "error rate on test set = 57.602274959737606 percent\n",
    "epoch= 199 \t time= 16.81212347348531 min \t loss= 1.4205077726816393 \t error= 54.08247543364456 percent\n",
    "error rate on test set = 57.27272792295977 percent\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD + Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum SGD\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "'''\n",
    "See log/vgg_optimizer_sgd_momentum.txt for the full output.\n",
    "\n",
    "epoch= 197 \t time= 17.621728281180065 min \t loss= 0.31581137352383015 \t error= 11.175260347189363 percent\n",
    "error rate on test set = 47.12500084530223 percent\n",
    "epoch= 198 \t time= 17.705276453495024 min \t loss= 0.3418008195063503 \t error= 12.350518064400584 percent\n",
    "error rate on test set = 47.30681831186468 percent\n",
    "epoch= 199 \t time= 17.794385369618734 min \t loss= 0.31510837414522763 \t error= 11.711342617408517 percent\n",
    "error rate on test set = 44.95454647324302 percent\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "'''\n",
    "See log/vgg_optimizer_adam.txt for the full output.\n",
    "\n",
    "epoch= 197 \t time= 14.945561536153157 min \t lr= 0.0001 \t loss= 0.21837057687879838 \t error= 8.247424523854994 percent\n",
    "error rate on test set = 46.76136482845653 percent\n",
    "epoch= 198 \t time= 15.016908542315166 min \t lr= 0.0001 \t loss= 0.239205996246682 \t error= 8.536084964103305 percent\n",
    "error rate on test set = 45.306819677352905 percent\n",
    "epoch= 199 \t time= 15.092707566420238 min \t lr= 0.0001 \t loss= 0.23558733973306478 \t error= 8.247424953991604 percent\n",
    "error rate on test set = 49.977273832667954 percent\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model Using Standard Dataset\n",
    "We train our model a public dataset [fer-2013](https://www.kaggle.com/msambare/fer2013).\n",
    "\n",
    "The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP31pe5+tcH8nejurDdKpdI",
   "collapsed_sections": [],
   "name": "VGG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
