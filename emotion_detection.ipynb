{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f365c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6fd11",
   "metadata": {},
   "source": [
    "# Dataset Collection\n",
    "\n",
    "## Assignee: \n",
    "+ Wen Hao: Build scraper module to gather images of faces\n",
    "+ Gin, Xiaoxin: Data cleaning. Remove images with inaccuracy label manually.\n",
    "\n",
    "## Description:\n",
    "\n",
    "We have chosen to gather our images from Google Image search, by searching for faces with the specified emotion, e.g. `\"happy man face\"`. For example, the raw images obtained using the search keyword \"happy man face\" would have the true labels `\"happy\"` and `\"man\"`. Adding the word `\"face\"` to the search term was to reduce the amount of images that might not have any face. This would form the raw dataset of our project.\n",
    "\n",
    "Collection of data was done via Selenium, a powerful tool for performing browser automation. It is used to automate the scraping from Google Images using the chromedriver. \n",
    "\n",
    "The steps for scraping the images are as follows:\n",
    "1. Open a **headless** browser and navigate to \"https://www.google.com/search?q={search_term}&tbm=isch&ijn=0\"\n",
    "  - The parameter `tbm=isch` specifies that this is an image search\n",
    "  - The parameter `q={search_term}` is the term to search for\n",
    "2. Keep scrolling down until all results are loaded in page\n",
    "3. Loop through each image result to get its URL with full resolution (not thumbnail)\n",
    "4. Download the image from the URL\n",
    "\n",
    "The above steps were repeated for all 14 search terms (7 emotions and 2 genders). There is also about a 3 seconds wait between each image in the loop as there is a need to wait for the UI to load to get the full resolution image. Hence, the challenge that we've met while trying to run this locally (on our Macbooks) is that this takes quite a significant amount of time if we run this sequentially one by one on our own laptop.\n",
    "\n",
    "The next approach to speed this up was to distribute this image search, to run all 14 searches in parallel. To do this, we build a docker container with the scraper and its dependencies built in and build an Airflow DAG (directed acyclic graph) run this on an instance of Airflow, with the search term as a parameter. \n",
    "\n",
    "However, the next challenge we found was that Selenium WebDriver/Chromedriver works very differently when running on a Linux based container, oftenly throwing the cryptic error `Selenium::WebDriver::Error::InvalidSessionIdError: invalid session id`. In Linux operating systems there is a shared memory space called `/dev/shm`. Any Linux process can create a partition within `/dev/shm` if the process wants to share memory with another process. This is often done to improve performance of similar processes. The shared memory space is often used by web browsers such as chrome when they’re being orchestrated by a selenium web driver. The solution was to mount memory to the path `/dev/shm`\n",
    "\n",
    "While trying to run a single search, I also realised that the WebDriver session seems to only be active for about 30 minutes and beyond that, most containers will start having session timeout errors whie trying to retrieve the image elements.\n",
    "\n",
    "Hence, we implemented a way to save progress at periodic checkpoints and resume the search from the index that it failed. With this, the overall solution was a brute force solution where we just increase the CPU and memory limit to the maximum possible and keep running it until we have saved all our results. The only caveat is that the image result is not static and the number of results we get is always changing, hence resuming from where we fail from a different search might end up having a slightly different set of results but it not very significant in this case.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Airflow Screenshots\n",
    "\n",
    "Below are the records of the total runs we have from the Airflow UI.\n",
    "\n",
    "![scrape-man](images/scrape-man.png)\n",
    "\n",
    "![scrape-woman](images/scrape-woman.png)\n",
    "\n",
    "![download-preprocess](images/download-preprocess.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Resource Monitoring\n",
    "\n",
    "We have also setup grafana to monitor the resource usage:\n",
    "\n",
    "![monitor](images/monitor.png)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "From the above chart, we can see that the amount of resources used was linearly increasing as times go on until a point and drops back down to 0. This suggest that there is a possible memory leakage somewhere within the implementation of Selenium WebDriver/Chromedriver. As time was limited, we kind of resolve this by adding checkpoints and brute forcing it by providing more compute resources for it to run to completion. \n",
    "\n",
    "Selenium might not have been the best tool for this scraping and we can explore other tools in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30088d31",
   "metadata": {},
   "source": [
    "### Scraper Demo \n",
    "\n",
    "The next cell we will run this scraper in dev mode which will only scrape the first 20 images to show how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e44246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: scraper.py [-h] [-s S] [-o O] [-r R] [-d D]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help  show this help message and exit\n",
      "  -s S        search term to scrape images from\n",
      "  -o O        output root directory\n",
      "  -r R        index to resume from\n",
      "  -d D        whether to run in dev mode\n"
     ]
    }
   ],
   "source": [
    "!python scraper.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac99f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WDM] - \n",
      "\n",
      "[2021-11-13 21:40:01,342] [INFO] - \n",
      "\n",
      "[WDM] - ====== WebDriver manager ======\n",
      "[2021-11-13 21:40:01,342] [INFO] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 95.0.4638\n",
      "[2021-11-13 21:40:01,401] [INFO] - Current google-chrome version is 95.0.4638\n",
      "[WDM] - Get LATEST driver version for 95.0.4638\n",
      "[2021-11-13 21:40:01,401] [INFO] - Get LATEST driver version for 95.0.4638\n",
      "[WDM] - Driver [/Users/wenhao.lau/.wdm/drivers/chromedriver/mac64/95.0.4638.69/chromedriver] found in cache\n",
      "[2021-11-13 21:40:01,460] [INFO] - Driver [/Users/wenhao.lau/.wdm/drivers/chromedriver/mac64/95.0.4638.69/chromedriver] found in cache\n",
      "[2021-11-13 21:40:02,269] [INFO] - Search term: sad man face\n",
      "[2021-11-13 21:40:03,901] [INFO] - Scrolling down ..\n",
      "[2021-11-13 21:40:22,237] [INFO] - Reached the end ..\n",
      "[2021-11-13 21:40:22,383] [INFO] - Total results found: 703\n",
      "[2021-11-13 21:40:22,383] [INFO] - is_retry: False\n",
      "[2021-11-13 21:40:22,383] [INFO] - dev: True\n",
      "search_term=sad man face | is_retry=False : 100%|█| 20/20 [01:06<00:00,  3.34s/i\n",
      "[2021-11-13 21:41:29,278] [INFO] - Total image URLs extracted in first pass: 20\n"
     ]
    }
   ],
   "source": [
    "!python scraper.py -s \"sad man face\" -d true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21799b65",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "Assignee: Wen Hao\n",
    "\n",
    "Description: Pre-process the images gathered. Standard image size, grayscale, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088ffc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b447ec6",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "Assignee: Gin, Xiaoxin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26f0a279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th># of sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral man face</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sad woman face</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>angry woman face</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgusted woman face</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy man face</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surprised woman face</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sad man face</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scared man face</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>angry man face</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>disgusted man face</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>scared woman face</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>happy woman face</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neutral woman face</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>surprised man face</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                category  # of sample\n",
       "0       neutral man face          241\n",
       "1         sad woman face          848\n",
       "2       angry woman face          753\n",
       "3   disgusted woman face          746\n",
       "4         happy man face          192\n",
       "5   surprised woman face          851\n",
       "6           sad man face          359\n",
       "7        scared man face          394\n",
       "8         angry man face          331\n",
       "9     disgusted man face          514\n",
       "10     scared woman face          825\n",
       "11      happy woman face          921\n",
       "12    neutral woman face          628\n",
       "13    surprised man face          378"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_FOLDER = # replace it with your own path\n",
    "\n",
    "totalImages = {}\n",
    "for subfolder in os.listdir(IMAGE_FOLDER):\n",
    "    dir = IMAGE_FOLDER + '/' + subfolder\n",
    "    if os.path.isdir(dir):\n",
    "        totalImages[subfolder] = len(os.listdir(dir))\n",
    "\n",
    "pd.DataFrame(totalImages.items(), columns = ['category', '# of sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4080d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7981 files in total.\n"
     ]
    }
   ],
   "source": [
    "print(sum(totalImages.values()), \"files in total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52f8d9",
   "metadata": {},
   "source": [
    "# Model Development, Improvement & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2fdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
